# Harjoitusty√∂ 2: Datan ker√§ys
### *Ilpo Viertola, Johdanto datatieteeseen 2021*

T√§ss√§ harjoitusty√∂n raportissa k√§yn l√§vitse, kuinka ker√§sin ty√∂ss√§ k√§ytetyn datasetin. Datasetit hain kahdesta eri l√§hteest√§:  
1. Kagglen tarjoama valmis datasetti  
2. Twitter API:n ja Tweepyn avulla itse ker√§tty datasetti  

## Kagglen tarjoama datasetti
  
K√§ytetyn datasetin l√∂yt√§√§ [t√§√§lt√§](https://www.kaggle.com/elvinagammed/covid19-fake-news-dataset-nlp/code). T√§m√§ datasetti koostuu eri sosiaalisen median kanavista ker√§tyist√§ englannin kielisist√§ julkaisuista, jotka sis√§lt√§v√§t Koronavirukseen liittyv√§√§ informaatiota. Datasetti my√∂s sis√§lt√§√§ tiedon siit√§, onko julkaisun informaatio paikkaansa pit√§v√§√§. T√§m√§n datasetin avulla pyrin harjoitusty√∂n seuraavissa vaiheissa opettamaan luokittelijan, joka osaa tunnistaa v√§√§r√§√§ Koronavirus informaatiota sis√§lt√§v√§t julkaisut. K√§yt√§n t√§st√§ datasetist√§ p√§√§s√§√§nt√∂isesti kahta eri tiedostoa harjoitusty√∂n seuraavissa vaiheissa:  
  
1. Constraint_Train.csv: Sis√§lt√§√§ opetusdatan.  
2. Constraint_Test.csv: Sis√§lt√§√§ testidatan.  
  
## Tweepyn avulla ker√§tty datasetti
  
K√§ytin Pythonin Tweepy kirjastoa, joka suoraviivaistaa Twitter API:n k√§ytt√∂√§. Twitter API mahdollistaa esimerkiksi twiittien reaaliaikaisen hakemisen Twitterist√§ ohjelmakoodissa. T√§m√§n ker√§tyn datasetin avulla pyrin koeponnistamaan tekem√§√§ni mallia reaalimaailmassa, eli luokittelemaan satunnaisia twiittej√§. Twiitit, joita ty√∂ss√§ k√§yt√§n ovat englannin kielisi√§ ja sis√§lt√§v√§t #covid19-tagin. N√§in voidaan olettaa, ett√§ twiitin sis√§lt√∂ liittyy edes jotenkin koronaviirukseen. On mielenkiintoista n√§hd√§, miten luokittelija k√§ytt√§ytyy heikommin kuratoiduille sy√∂tteille. Alla on esitettyn√§ Python-koodi, jota twiittien hakemiseen k√§ytin.   


```python
import tweepy
import pandas as pd

# Autentikointi Twitteriin
consumer_key = ''
consumer_secret = ''
access_key = ''
access_key_secret = ''

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_key_secret)
api = tweepy.API(auth)  # Rajapinta

# Luodaan DataFrame twiiteille
tweet_df = pd.DataFrame(columns=['username', 'description', 'location', 'following', 'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])

# Tweepyn Cursor-objektille annetaan parametrina api.search-metodi ja haun parametrit. 
# Rajoitetaan haettavien twiittien m√§√§r√§ esim. 50:neen.
hashtag = '#covid19'
d_since = '2021-04-07'
limit = 50
tweets = tweepy.Cursor(api.search, q=hashtag, lang='en', since=d_since, tweet_mode='extended').items(limit)

# Cursor palauttaa iteroitavat objektin, joten iteroidaan sen sis√§lt√∂ listaan.
tweets_list = [tweet for tweet in tweets]

# K√§yd√§√§n l√§pi twiitit listasta.
for tweet in tweets_list:
    # Tietoja twiitist√§ ja twiittaajasta my√∂hemp√§√§n tarkasteluun
    username = tweet.user.screen_name
    description = tweet.user.description
    location = tweet.user.location
    following = tweet.user.friends_count
    followers = tweet.user.followers_count
    totaltweets = tweet.user.statuses_count
    retweetcount = tweet.retweet_count
    hashtags = tweet.entities['hashtags']
        
    # Uudelleentwiittaukset voidaan erottaa retweeted_status-m√§√§ritteell√§.
    # Jos twiitti ei ole retwiitti, except-lohko suoritetaan.
    try:
        text = tweet.retweeted_status.full_text
    except AttributeError:
        text = tweet.full_text
    hashtext = list()
    for j in range(0, len(hashtags)):
        hashtext.append(hashtags[j]['text'])
        
    # Lis√§t√§√§n data DataFrameen.
    ith_tweet = [username, description, location, following, followers, totaltweets, retweetcount, text, hashtext]
    tweet_df.loc[len(tweet_df)] = ith_tweet

# Rivien m√§√§r√§ sama kuin asetettu raja.
print('Amount of tweets: ' + str(len(tweet_df)))
# Katsaus muutamaan ensimm√§iseen riviin.
tweet_df.head()
```

    Amount of tweets: 50





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>username</th>
      <th>description</th>
      <th>location</th>
      <th>following</th>
      <th>followers</th>
      <th>totaltweets</th>
      <th>retweetcount</th>
      <th>text</th>
      <th>hashtags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Sampath1986</td>
      <td>Filmmaker, Indian cinema</td>
      <td>Chennai, India</td>
      <td>919</td>
      <td>161</td>
      <td>52645</td>
      <td>4</td>
      <td>#Lucknow\nNeed #Blood Type :  O-negative\nAt :...</td>
      <td>[Lucknow, Blood, COVID19]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>DbAshby</td>
      <td>Brexit is a disaster for the UK economy #Brexi...</td>
      <td>Cheshire</td>
      <td>6259</td>
      <td>5986</td>
      <td>303793</td>
      <td>243</td>
      <td>"Vaccines alone will not be able to protect us...</td>
      <td>[COVID19]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SEEP_Fiji</td>
      <td>People. Centred. Development. \nReal DEMOCRACY</td>
      <td>Suva,  Fiji</td>
      <td>197</td>
      <td>241</td>
      <td>1273</td>
      <td>0</td>
      <td>Demystify all the fear mongering around the #C...</td>
      <td>[COVID19, vaccine]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>yodisculpe</td>
      <td>27 üá≤üáΩ \nAlways hungry/always tired. Wear a mas...</td>
      <td>L.A.</td>
      <td>218</td>
      <td>14</td>
      <td>5964</td>
      <td>109</td>
      <td>L.A. PEOPLE: Just checked and there are some #...</td>
      <td>[COVID19]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SOUMYA_PAL24</td>
      <td></td>
      <td></td>
      <td>0</td>
      <td>0</td>
      <td>52</td>
      <td>52</td>
      <td>Doing online meeting to secure themselves and ...</td>
      <td>[Examwarrior]</td>
    </tr>
  </tbody>
</table>
</div>



## Hy√∂dyllisi√§ linkkej√§
1. [Kagglen datasetti](https://www.kaggle.com/elvinagammed/covid19-fake-news-dataset-nlp?select=Constraint_Test.csv)
2. [Tweepyn dokumentaatio](https://docs.tweepy.org/en/latest/index.html)
3. [Geeks4Geeks esimerkki](https://www.geeksforgeeks.org/extracting-tweets-containing-a-particular-hashtag-using-python/)

## Helppoa ja haastavaa
1. Kagglesta hyv√§n ja ajankohtaisen datasetin etsiminen saattaa vaati hieman aikaa.  
2. Tweepy oli t√§ysin uusi tuttavuus, joten sen omaksuminen otti aikansa.  
3. Twitter API:n datanker√§ys katot aiheuttivat v√§lill√§ p√§√§nvaivaa. 
