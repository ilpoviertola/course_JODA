{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0a6d4ddde8f020d22769858c6343faf50cf54e29c922f4da84f6f66e8323f4169",
   "display_name": "Python 3.7.10 64-bit ('JODA': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Johdanto Datatieteeseen 2021 -practical work\n",
    "### *author: Ilpo Viertola*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/ilpoviertola/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Normal stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Twitter API\n",
    "import tweepy\n",
    "import ast\n",
    "\n",
    "# Tweet preprocessing\n",
    "import nltk\n",
    "# Download nltk-packages (not downloaded if up to date)\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import html\n",
    "import string"
   ]
  },
  {
   "source": [
    "## Reading the data\n",
    "**Read the data in from [Kaggle csv-files](https://www.kaggle.com/elvinagammed/covid19-fake-news-dataset-nlp) and with Twitter API.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  Chinese converting to Islam after realising th...  fake\n",
       "1   2  11 out of 13 people (from the Diamond Princess...  fake\n",
       "2   3  COVID-19 Is Caused By A Bacterium, Not Virus A...  fake\n",
       "3   4  Mike Pence in RNC speech praises Donald Trumpâ€™...  fake\n",
       "4   5  6/10 Sky's @EdConwaySky explains the latest #C...  real"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Chinese converting to Islam after realising th...</td>\n      <td>fake</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>11 out of 13 people (from the Diamond Princess...</td>\n      <td>fake</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n      <td>fake</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Mike Pence in RNC speech praises Donald Trumpâ€™...</td>\n      <td>fake</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n      <td>real</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "csv_path = '/Users/ilpoviertola/OneDrive - TUNI.fi/Kurssimateriaaleja/JODA/datasets/covid19_fake_news'\n",
    "# Data to train the model with\n",
    "train_df = pd.read_csv(csv_path + '/Constraint_Train.csv')\n",
    "train_df.head()\n",
    "# Data to test the model with\n",
    "test_df = pd.read_csv(csv_path + '/Constraint_Test.csv')\n",
    "test_df.head()\n",
    "# Data to validate the model with\n",
    "val_df = pd.read_csv(csv_path + '/Constraint_Val.csv')\n",
    "val_df.head()"
   ]
  },
  {
   "source": [
    "**Next Twitter data. First lets authenticate ourselves so we can use Twitter API.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Twitter API-keys from a local file.\n",
    "key_file = open('twitter.key', 'r')\n",
    "keys = ast.literal_eval(key_file.read())\n",
    "key_file.close()\n",
    "\n",
    "auth = tweepy.OAuthHandler(keys['API'], keys['API_secret'])\n",
    "auth.set_access_token(keys['Access_token'], keys['Access_token_secret'])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "source": [
    "**Create DataFrame where the tweets are stored and fetch tweets.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for tweets\n",
    "tweet_df = pd.DataFrame(columns=['username', 'description', 'location', 'following', 'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])\n",
    "\n",
    "# Get tweets\n",
    "hashtag = '#covid19'\n",
    "d_since = '2021-04-07'\n",
    "limit = 250\n",
    "tweets = tweepy.Cursor(api.search, q=hashtag, lang='en', since=d_since, tweet_mode='extended').items(limit)\n",
    "tweets_list = [tweet for tweet in tweets]"
   ]
  },
  {
   "source": [
    "**Process tweets and add them to DataFrame. We'll exclude retweets.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          username                                        description  \\\n",
       "0       sfomorales  Mexicano-Americano ðŸ‡²ðŸ‡½ðŸ‡ºðŸ‡¸ Aspiring francophileðŸ¥– ...   \n",
       "1        COVIDLive  COVID-19 (Coronavirus) Latest News & Statistic...   \n",
       "2       DrAzad_786  Professor ~ Researcher ~ Guide ~ Analyst \\n\\nl...   \n",
       "3       Mlakcreddy                                  Proud to IndianðŸ‡®ðŸ‡³   \n",
       "4  Priyans89522585                                                      \n",
       "\n",
       "            location following followers totaltweets retweetcount  \\\n",
       "0  San Francisco, CA       229        71         190            0   \n",
       "1                            2       911       58013            0   \n",
       "2            Kashmir      1667       976          83            0   \n",
       "3          Bangalore       112       162        7515            0   \n",
       "4                            3         1          44            0   \n",
       "\n",
       "                                                text  \\\n",
       "0  ðŸš¨ #BreakingNews from @SpartanDaily: CA #CSU wi...   \n",
       "1  26 new cases in Singapore \\n\\n[9:52 GMT] #coro...   \n",
       "2  #Pakistan is highlighting #Kashmir issue in #U...   \n",
       "3  Income tax payers should be given Vaccine Fris...   \n",
       "4  @1mgOfficial my sample was Collected for #COVI...   \n",
       "\n",
       "                                            hashtags  \n",
       "0  [BreakingNews, CSU, vaccine, COVIDãƒ¼19, COVID19...  \n",
       "1  [coronavirus, CoronaVirusUpdate, COVID19, Coro...  \n",
       "2  [Pakistan, Kashmir, UN, ethnic, religious, Bal...  \n",
       "3                             [vaccination, COVID19]  \n",
       "4  [COVID19, Labreports, FLIGHT, badcustomerservice]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>description</th>\n      <th>location</th>\n      <th>following</th>\n      <th>followers</th>\n      <th>totaltweets</th>\n      <th>retweetcount</th>\n      <th>text</th>\n      <th>hashtags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sfomorales</td>\n      <td>Mexicano-Americano ðŸ‡²ðŸ‡½ðŸ‡ºðŸ‡¸ Aspiring francophileðŸ¥– ...</td>\n      <td>San Francisco, CA</td>\n      <td>229</td>\n      <td>71</td>\n      <td>190</td>\n      <td>0</td>\n      <td>ðŸš¨ #BreakingNews from @SpartanDaily: CA #CSU wi...</td>\n      <td>[BreakingNews, CSU, vaccine, COVIDãƒ¼19, COVID19...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COVIDLive</td>\n      <td>COVID-19 (Coronavirus) Latest News &amp; Statistic...</td>\n      <td></td>\n      <td>2</td>\n      <td>911</td>\n      <td>58013</td>\n      <td>0</td>\n      <td>26 new cases in Singapore \\n\\n[9:52 GMT] #coro...</td>\n      <td>[coronavirus, CoronaVirusUpdate, COVID19, Coro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DrAzad_786</td>\n      <td>Professor ~ Researcher ~ Guide ~ Analyst \\n\\nl...</td>\n      <td>Kashmir</td>\n      <td>1667</td>\n      <td>976</td>\n      <td>83</td>\n      <td>0</td>\n      <td>#Pakistan is highlighting #Kashmir issue in #U...</td>\n      <td>[Pakistan, Kashmir, UN, ethnic, religious, Bal...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mlakcreddy</td>\n      <td>Proud to IndianðŸ‡®ðŸ‡³</td>\n      <td>Bangalore</td>\n      <td>112</td>\n      <td>162</td>\n      <td>7515</td>\n      <td>0</td>\n      <td>Income tax payers should be given Vaccine Fris...</td>\n      <td>[vaccination, COVID19]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Priyans89522585</td>\n      <td></td>\n      <td></td>\n      <td>3</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0</td>\n      <td>@1mgOfficial my sample was Collected for #COVI...</td>\n      <td>[COVID19, Labreports, FLIGHT, badcustomerservice]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "for tweet in tweets_list:\n",
    "    # Data about tweets\n",
    "    username = tweet.user.screen_name\n",
    "    description = tweet.user.description\n",
    "    location = tweet.user.location\n",
    "    following = tweet.user.friends_count\n",
    "    followers = tweet.user.followers_count\n",
    "    totaltweets = tweet.user.statuses_count\n",
    "    retweetcount = tweet.retweet_count\n",
    "    hashtags = tweet.entities['hashtags']\n",
    "    \n",
    "    # Let's ignore all retweets\n",
    "    if not tweet.retweeted and ('RT @' not in tweet.full_text):\n",
    "\n",
    "        text = tweet.full_text\n",
    "        hashtext = list()\n",
    "        for j in range(0, len(hashtags)):\n",
    "            hashtext.append(hashtags[j]['text'])\n",
    "            \n",
    "        # LisÃ¤tÃ¤Ã¤n data DataFrameen.\n",
    "        ith_tweet = [username, description, location, following, followers, totaltweets, \n",
    "                    retweetcount, text, hashtext]\n",
    "        tweet_df.loc[len(tweet_df)] = ith_tweet\n",
    "\n",
    "tweet_df.head()"
   ]
  },
  {
   "source": [
    "## Check for Null-values "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Null values in training data? False\nNull values in testing data? False\nNull values in validation data? False\nNull values in Twitter data? False\n"
     ]
    }
   ],
   "source": [
    "print('Null values in training data? ' + str(train_df.isnull().values.any()))\n",
    "print('Null values in testing data? ' + str(test_df.isnull().values.any()))\n",
    "print('Null values in validation data? ' + str(val_df.isnull().values.any()))\n",
    "print('Null values in Twitter data? ' + str(tweet_df.isnull().values.any()))"
   ]
  },
  {
   "source": [
    "## Data exploration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Check column names**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training & validation data's columns:\n['id' 'tweet' 'label']\n['id' 'tweet' 'label']\nTest data's columns:\n['id' 'tweet']\nTwitter data's columns:\n['username' 'description' 'location' 'following' 'followers' 'totaltweets'\n 'retweetcount' 'text' 'hashtags']\n"
     ]
    }
   ],
   "source": [
    "print('Training & validation data\\'s columns:')\n",
    "print(train_df.columns.values)\n",
    "print(val_df.columns.values)\n",
    "print('Test data\\'s columns:')\n",
    "print(test_df.columns.values)\n",
    "print('Twitter data\\'s columns:')\n",
    "print(tweet_df.columns.values)"
   ]
  },
  {
   "source": [
    "**Columns are ok. Next check datatypes**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datatypes for training data: \nid        int64\ntweet    object\nlabel    object\ndtype: object\n\nDatatypes for validation data: \nid        int64\ntweet    object\nlabel    object\ndtype: object\n\nDatatypes for testing data: \nid        int64\ntweet    object\ndtype: object\n\nDatatypes for Twitter data: \nusername        object\ndescription     object\nlocation        object\nfollowing       object\nfollowers       object\ntotaltweets     object\nretweetcount    object\ntext            object\nhashtags        object\ndtype: object\n\n"
     ]
    }
   ],
   "source": [
    "print('Datatypes for training data: \\n' + str(train_df.dtypes) + '\\n')\n",
    "print('Datatypes for validation data: \\n' + str(val_df.dtypes) + '\\n')\n",
    "print('Datatypes for testing data: \\n' + str(test_df.dtypes) + '\\n')\n",
    "print('Datatypes for Twitter data: \\n' + str(tweet_df.dtypes) + '\\n')"
   ]
  },
  {
   "source": [
    "**Twitter dataset needs some datatype modifications.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New datatypes for Twitter data: \nusername        object\ndescription     object\nlocation        object\nfollowing        int32\nfollowers        int32\ntotaltweets      int32\nretweetcount     int32\ntext            object\nhashtags        object\ndtype: object\n\n"
     ]
    }
   ],
   "source": [
    "tweet_df = tweet_df.astype({'following': 'int32', 'followers': 'int32', \n",
    "                            'totaltweets': 'int32', 'retweetcount': 'int32'})\n",
    "print('New datatypes for Twitter data: \\n' + str(tweet_df.dtypes) + '\\n')"
   ]
  },
  {
   "source": [
    "print('\\nExample tweet from training data: ')\n",
    "print(train_df['tweet'][5])\n",
    "print('\\nExample tweet from Twitter data: ')\n",
    "print(tweet_df['text'][5])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nExample tweet from training data: \nCovid Act Now found \"on average each person in Illinois with COVID-19 is infecting 1.11 other people. Data shows that the infection growth rate has declined over time this factors in the stay-at-home order and other restrictions put in place.\" https://t.co/hhigDd24fE\n\nExample tweet from Twitter data: \nFrom 12 March, employees in New York State are entitled to four hoursâ€™ paid leave to enable them to get a #COVID19 #vaccination. Our @IusLaboris colleagues have summarized this novelty:\n\nhttps://t.co/0EwkW13Sfj\n\n#labourlaw #coronavirus #paidleave #newyork #USA https://t.co/bHPMh16ZqK\n"
     ]
    }
   ]
  },
  {
   "source": [
    "**Tweets typically contain links, other people's usernames, hashtags and emojis. These must be cleaned before training the model...**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data labels: \n real    3360\nfake    3060\nName: label, dtype: int64\n\nValidation data labels: \n real    1120\nfake    1020\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training data labels: \\n', train_df['label'].value_counts())\n",
    "print('\\nValidation data labels: \\n', val_df['label'].value_counts())"
   ]
  },
  {
   "source": [
    "**Datasets are balanced, meaning they contain approximately as much fake and real news. These values must be binarycoded in the future.**  \n",
    "  \n",
    "## Tweet preprocessing aka. feature extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}